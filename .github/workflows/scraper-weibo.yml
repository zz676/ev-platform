name: EV News Scraper - Weibo

on:
  schedule:
    - cron: '10 */6 * * *'  # Every 6 hours, offset 10 min from official sites
  workflow_dispatch:  # Manual trigger

jobs:
  scrape:
    runs-on: ubuntu-latest
    timeout-minutes: 15

    steps:
      - name: Log workflow start
        run: |
          echo "=========================================="
          echo "EV News Scraper - Weibo"
          echo "=========================================="
          echo "Triggered by: ${{ github.event_name }}"
          echo "Run ID: ${{ github.run_id }}"
          echo "Sources: weibo"
          echo "Start time: $(date -u '+%Y-%m-%d %H:%M:%S UTC')"
          echo "=========================================="

      - uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          cache: 'pip'
          cache-dependency-path: scraper/requirements.txt

      - name: Install dependencies
        run: |
          cd scraper
          pip install -r requirements.txt

      - name: Install Playwright browsers
        run: |
          echo "Installing Playwright Chromium..."
          playwright install chromium
          echo "Playwright installed successfully"

      - name: Validate secrets
        run: |
          echo "Validating required secrets..."
          missing_secrets=""

          if [ -z "${{ secrets.WEBHOOK_URL }}" ]; then
            missing_secrets="$missing_secrets WEBHOOK_URL"
          else
            echo "WEBHOOK_URL is set"
          fi

          if [ -z "${{ secrets.SCRAPER_WEBHOOK_SECRET }}" ]; then
            missing_secrets="$missing_secrets SCRAPER_WEBHOOK_SECRET"
          else
            echo "SCRAPER_WEBHOOK_SECRET is set"
          fi

          if [ -z "${{ secrets.DEEPSEEK_API_KEY }}" ] && [ -z "${{ secrets.OPENAI_API_KEY }}" ]; then
            echo "WARNING: Neither DEEPSEEK_API_KEY nor OPENAI_API_KEY is set"
          else
            [ -n "${{ secrets.DEEPSEEK_API_KEY }}" ] && echo "DEEPSEEK_API_KEY is set"
            [ -n "${{ secrets.OPENAI_API_KEY }}" ] && echo "OPENAI_API_KEY is set"
          fi

          if [ -n "$missing_secrets" ]; then
            echo "ERROR: Missing required secrets:$missing_secrets"
            exit 1
          fi

      - name: Run scraper (Weibo only)
        run: |
          echo "=========================================="
          echo "Starting scraper for Weibo..."
          echo "=========================================="

          python scraper/main.py --sources weibo
          exit_code=$?

          echo "=========================================="
          echo "Scraper finished with exit code: $exit_code"
          echo "End time: $(date -u '+%Y-%m-%d %H:%M:%S UTC')"
          echo "=========================================="

          exit $exit_code
        env:
          DEEPSEEK_API_KEY: ${{ secrets.DEEPSEEK_API_KEY }}
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
          WEBHOOK_URL: ${{ secrets.WEBHOOK_URL }}
          SCRAPER_WEBHOOK_SECRET: ${{ secrets.SCRAPER_WEBHOOK_SECRET }}
          CRON_SECRET: ${{ secrets.CRON_SECRET }}
          SKIP_X_PUBLISH: 'true'

      - name: Log failure details
        if: failure()
        run: |
          echo "=========================================="
          echo "SCRAPER FAILED (Weibo)"
          echo "=========================================="
          echo "Check the logs above for error details"
          echo "Common Weibo-specific issues:"
          echo "  - Visitor cookie/session expired"
          echo "  - Rate limited by Weibo anti-bot"
          echo "  - Playwright browser launch failure"
          echo "=========================================="
