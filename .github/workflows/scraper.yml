name: EV News Scraper

on:
  schedule:
    - cron: '0 */6 * * *'  # Every 6 hours (0, 6, 12, 18 UTC)
  workflow_dispatch:  # Manual trigger

jobs:
  scrape:
    runs-on: ubuntu-latest
    timeout-minutes: 30

    steps:
      - uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          cache: 'pip'
          cache-dependency-path: scraper/requirements.txt

      - name: Install dependencies
        run: |
          cd scraper
          pip install -r requirements.txt

      - name: Install Playwright browsers
        run: playwright install chromium

      - name: Run scraper
        run: python scraper/main.py
        env:
          DEEPSEEK_API_KEY: ${{ secrets.DEEPSEEK_API_KEY }}
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
          WEBHOOK_URL: ${{ secrets.WEBHOOK_URL }}
          SCRAPER_WEBHOOK_SECRET: ${{ secrets.SCRAPER_WEBHOOK_SECRET }}
          CRON_SECRET: ${{ secrets.CRON_SECRET }}
          SKIP_X_PUBLISH: 'true'  # X publishing handled by cron-publish.yml
